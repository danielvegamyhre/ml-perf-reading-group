# Session 11: Async Tensor Parallelism

EleutherAI ML Scalability & Performance Reading Group Session 11 meeting recording, where we covered the paper  "Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models," as well as how it is implemented in PyTorch as "async tensor parallelism."

Presenter: Daniel Vega-Myhre

### Links:
- [Paper: Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models](./overlapping-communication-and-computation-via-decomposition.pdf)
- My blog post: [An illustrated deep-dive into how the compute and comms in TP+SP are overlapped using Async TP](https://danielvegamyhre.github.io/ml/performance/2025/05/26/async-tp.html)
- [Meeting recording](https://youtu.be/Ow1FLKFcSPs?si=KANmECRX1vRt4C_W)
